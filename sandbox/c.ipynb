{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mbgl/Desktop/dev/compilers/at1/sandbox', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python312.zip', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12/lib-dynload', '', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12/site-packages']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'ArrayType',\n",
       " 'BinOp',\n",
       " 'Callable',\n",
       " 'CharacterLiteral',\n",
       " 'Comment',\n",
       " 'Enum',\n",
       " 'Err',\n",
       " 'Expr',\n",
       " 'FloatingLiteral',\n",
       " 'Generator',\n",
       " 'Ident',\n",
       " 'In',\n",
       " 'IntegerConstantBase',\n",
       " 'IntegerConstantType',\n",
       " 'IntegerLiteral',\n",
       " 'KEYWORDS',\n",
       " 'Keyword',\n",
       " 'Lexer',\n",
       " 'LexerError',\n",
       " 'LexerRet',\n",
       " 'LexerState',\n",
       " 'LineComment',\n",
       " 'Literal',\n",
       " 'MultilineComment',\n",
       " 'Ok',\n",
       " 'OkErr',\n",
       " 'Optional',\n",
       " 'Out',\n",
       " 'PUNCTUATOR_VALUES',\n",
       " 'ParseObject',\n",
       " 'Parser',\n",
       " 'ParserError',\n",
       " 'ParserRet',\n",
       " 'ParserState',\n",
       " 'Punct',\n",
       " 'Punctuator',\n",
       " 'Result',\n",
       " 'Self',\n",
       " 'Span',\n",
       " 'StringLiteral',\n",
       " 'Struct',\n",
       " 'Token',\n",
       " 'TraceBackEntry',\n",
       " 'TypeAlias',\n",
       " 'TypeVar',\n",
       " 'UnOp',\n",
       " 'UnreachableError',\n",
       " 'UnwrapError',\n",
       " 'VariableDeclarationStmt',\n",
       " '_',\n",
       " '_1',\n",
       " '_10',\n",
       " '_101',\n",
       " '_102',\n",
       " '_104',\n",
       " '_105',\n",
       " '_11',\n",
       " '_110',\n",
       " '_111',\n",
       " '_112',\n",
       " '_113',\n",
       " '_114',\n",
       " '_116',\n",
       " '_117',\n",
       " '_122',\n",
       " '_123',\n",
       " '_124',\n",
       " '_125',\n",
       " '_126',\n",
       " '_14',\n",
       " '_15',\n",
       " '_17',\n",
       " '_19',\n",
       " '_2',\n",
       " '_20',\n",
       " '_22',\n",
       " '_4',\n",
       " '_5',\n",
       " '_58',\n",
       " '_59',\n",
       " '_60',\n",
       " '_62',\n",
       " '_63',\n",
       " '_70',\n",
       " '_71',\n",
       " '_73',\n",
       " '_74',\n",
       " '_81',\n",
       " '_82',\n",
       " '_84',\n",
       " '_85',\n",
       " '_91',\n",
       " '_92',\n",
       " '_94',\n",
       " '_95',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__vsc_ipynb_file__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i100',\n",
       " '_i101',\n",
       " '_i102',\n",
       " '_i103',\n",
       " '_i104',\n",
       " '_i105',\n",
       " '_i106',\n",
       " '_i107',\n",
       " '_i108',\n",
       " '_i109',\n",
       " '_i11',\n",
       " '_i110',\n",
       " '_i111',\n",
       " '_i112',\n",
       " '_i113',\n",
       " '_i114',\n",
       " '_i115',\n",
       " '_i116',\n",
       " '_i117',\n",
       " '_i118',\n",
       " '_i119',\n",
       " '_i12',\n",
       " '_i120',\n",
       " '_i121',\n",
       " '_i122',\n",
       " '_i123',\n",
       " '_i124',\n",
       " '_i125',\n",
       " '_i126',\n",
       " '_i127',\n",
       " '_i13',\n",
       " '_i14',\n",
       " '_i15',\n",
       " '_i16',\n",
       " '_i17',\n",
       " '_i18',\n",
       " '_i19',\n",
       " '_i2',\n",
       " '_i20',\n",
       " '_i21',\n",
       " '_i22',\n",
       " '_i23',\n",
       " '_i24',\n",
       " '_i25',\n",
       " '_i26',\n",
       " '_i27',\n",
       " '_i28',\n",
       " '_i29',\n",
       " '_i3',\n",
       " '_i30',\n",
       " '_i31',\n",
       " '_i32',\n",
       " '_i33',\n",
       " '_i34',\n",
       " '_i35',\n",
       " '_i36',\n",
       " '_i37',\n",
       " '_i38',\n",
       " '_i39',\n",
       " '_i4',\n",
       " '_i40',\n",
       " '_i41',\n",
       " '_i42',\n",
       " '_i43',\n",
       " '_i44',\n",
       " '_i45',\n",
       " '_i46',\n",
       " '_i47',\n",
       " '_i48',\n",
       " '_i49',\n",
       " '_i5',\n",
       " '_i50',\n",
       " '_i51',\n",
       " '_i52',\n",
       " '_i53',\n",
       " '_i54',\n",
       " '_i55',\n",
       " '_i56',\n",
       " '_i57',\n",
       " '_i58',\n",
       " '_i59',\n",
       " '_i6',\n",
       " '_i60',\n",
       " '_i61',\n",
       " '_i62',\n",
       " '_i63',\n",
       " '_i64',\n",
       " '_i65',\n",
       " '_i66',\n",
       " '_i67',\n",
       " '_i68',\n",
       " '_i69',\n",
       " '_i7',\n",
       " '_i70',\n",
       " '_i71',\n",
       " '_i72',\n",
       " '_i73',\n",
       " '_i74',\n",
       " '_i75',\n",
       " '_i76',\n",
       " '_i77',\n",
       " '_i78',\n",
       " '_i79',\n",
       " '_i8',\n",
       " '_i80',\n",
       " '_i81',\n",
       " '_i82',\n",
       " '_i83',\n",
       " '_i84',\n",
       " '_i85',\n",
       " '_i86',\n",
       " '_i87',\n",
       " '_i88',\n",
       " '_i89',\n",
       " '_i9',\n",
       " '_i90',\n",
       " '_i91',\n",
       " '_i92',\n",
       " '_i93',\n",
       " '_i94',\n",
       " '_i95',\n",
       " '_i96',\n",
       " '_i97',\n",
       " '_i98',\n",
       " '_i99',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'as_async_result',\n",
       " 'as_result',\n",
       " 'auto',\n",
       " 'between',\n",
       " 'combinator',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'dataclass',\n",
       " 'df',\n",
       " 'do',\n",
       " 'do_async',\n",
       " 'e',\n",
       " 'err',\n",
       " 'err_sub',\n",
       " 'exit',\n",
       " 'field',\n",
       " 'get_ipython',\n",
       " 'ident',\n",
       " 'imp',\n",
       " 'inf',\n",
       " 'infer_span',\n",
       " 'is_err',\n",
       " 'is_ok',\n",
       " 'keyword',\n",
       " 'keyword_or_ident',\n",
       " 'l',\n",
       " 'lib',\n",
       " 'open',\n",
       " 'os',\n",
       " 'parse_arith_expr',\n",
       " 'parse_end_of_input',\n",
       " 'parse_escape_sequence',\n",
       " 'parse_increasing_precedence',\n",
       " 'parse_object',\n",
       " 'parse_object_unparse_default',\n",
       " 'parse_re',\n",
       " 'parse_string',\n",
       " 'parse_token_stream',\n",
       " 'parse_whitespace',\n",
       " 'parser_gen_runner',\n",
       " 'punct',\n",
       " 'quit',\n",
       " 'r',\n",
       " 're',\n",
       " 'rest',\n",
       " 's',\n",
       " 'skip_whitespace',\n",
       " 'suffix',\n",
       " 'sys',\n",
       " 't',\n",
       " 'token',\n",
       " 'tokenize',\n",
       " 'tokens',\n",
       " 'ts',\n",
       " 'wraps']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib as imp\n",
    "# imp.invalidate_caches()\n",
    "# sys.path.insert(1, '../lib/parsing')\n",
    "print(sys.path)\n",
    "os.path.abspath(os.curdir)\n",
    "os.__file__\n",
    "# from c_lexer import *\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.parsing.c.lexer\n",
    "import lib.parsing.c.parser\n",
    "import lib.parsing.combinator\n",
    "imp.reload(lib.parsing.c.lexer)\n",
    "imp.reload(lib.parsing.c.parser)\n",
    "imp.reload(lib.parsing.combinator)\n",
    "from lib.parsing.c.lexer import *\n",
    "from lib.parsing.c.parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok(('test', LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok(('test', LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok((Ident(name='test'), LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok((Keyword(ident=Ident(name='while')), LexerState(text='while', index=5, line=1, col=6)))\n",
      "Ok((Punct(value='<'), LexerState(text='<<', index=1, line=1, col=2)))\n",
      "Ok((Punct(value='['), LexerState(text='[]', index=1, line=1, col=2)))\n",
      "Err(LexerError(traceback=[TraceBackEntry(state=LexerState(text='_]', index=0, line=1, col=1), expected='punctuator', found='_', message='')]))\n",
      "s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Keyword(ident=Ident(name='while')),\n",
       "  Ident(name='true'),\n",
       "  Punct(value='{'),\n",
       "  Ident(name='statement'),\n",
       "  Punct(value='('),\n",
       "  Punct(value=')'),\n",
       "  Punct(value=';'),\n",
       "  Punct(value='}')],\n",
       " LexerState(text='while true\\n{statement();}', index=25, line=2, col=14))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = LexerState(\"test\")\n",
    "print(parse_string(\"test\")(s))\n",
    "print(parse_re(\"test\")(s))\n",
    "print(Ident.parse(s))\n",
    "s = LexerState(\"while\")\n",
    "print(Keyword.parse(s))\n",
    "print(Punct.parse(LexerState(\"<<\")))\n",
    "print(Punct.parse(LexerState(\"[]\")))\n",
    "print(Punct.parse(LexerState(\"_]\")))\n",
    "\n",
    "print(LexerState(\"state\")[0])\n",
    "\n",
    "s = LexerState(\"while true\\n{statement();}\")\n",
    "parse_token_stream(s).unwrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Keyword(ident=Ident(name='int')),\n",
       "  Ident(name='main'),\n",
       "  Punct(value='('),\n",
       "  Punct(value=')'),\n",
       "  Punct(value='{'),\n",
       "  Punct(value='}')],\n",
       " LexerState(text='int main() {}', index=13, line=1, col=14))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(\"int main() {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct test_s {\n",
      "    int i;\n",
      "    double d;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ts, rest = parse_token_stream(LexerState(\"struct test_s {\\nint i; double d;};\")).unwrap()\n",
    "# print(ts)\n",
    "t, r = Struct.parse(ParserState(ts)).unwrap()\n",
    "# t.body[0][0]\n",
    "print(t.unparse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (lexing) <file>:1:1:\n",
      "expected: test, found: tees \n",
      "teest\n"
     ]
    }
   ],
   "source": [
    "s = LexerState(\"teest\")\n",
    "# match parse_string(\"test\")(s):\n",
    "#     case Err(e):\n",
    "e = parse_string(\"test\")(s).unwrap_err() \n",
    "print(e.format_error(\"<file>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StringLiteral(value='text')\n",
      "CharacterLiteral(value='a')\n",
      "(LineComment(text=' whatever comment '), LexerState(text='// whatever comment \\n nope', index=20, line=1, col=21))\n",
      "(MultilineComment(text=' whatever\\n comment '), LexerState(text='/* whatever\\n comment */', index=23, line=2, col=11))\n"
     ]
    }
   ],
   "source": [
    "print(StringLiteral.parse(LexerState('\"text\"')).unwrap())\n",
    "print(CharacterLiteral.parse(LexerState(\"'a'\")).unwrap())\n",
    "print(LineComment.parse(LexerState('// whatever comment \\n nope')).unwrap())\n",
    "print(MultilineComment.parse(LexerState('/* whatever\\n comment */')).unwrap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('a')\n",
    "s = Span\n",
    "s()\n",
    "print(Ident(\"a\", Span(1)) == Ident(\"a\", Span(2)))\n",
    "print(Keyword(Ident(\"a\", Span(1))) == Keyword(Ident(\"a\", Span(2))))\n",
    "print(type(Ident('a')) is Ident)\n",
    "\n",
    "\n",
    "tokens = [Ident(\"test\")]\n",
    "s = ParserState(tokens)\n",
    "\n",
    "t, r = token(Ident)(s).unwrap()\n",
    "\n",
    "# raise UnreachableError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ok((IntegerLiteral(value=1045315, base=<IntegerConstantType.ULLONG: 'llu'>, type=<IntegerConstantBase.HEX: '0x'>), LexerState(text='0xff343ulll', index=10, line=1, col=11)))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntegerLiteral.parse(LexerState(\"0xff343ulll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auto',\n",
       " 'break',\n",
       " 'case',\n",
       " 'char',\n",
       " 'const',\n",
       " 'continue',\n",
       " 'default',\n",
       " 'do',\n",
       " 'double',\n",
       " 'else',\n",
       " 'enum',\n",
       " 'extern',\n",
       " 'float',\n",
       " 'for',\n",
       " 'goto',\n",
       " 'if',\n",
       " 'inline',\n",
       " 'int',\n",
       " 'long',\n",
       " 'register',\n",
       " 'restrict',\n",
       " 'return',\n",
       " 'short',\n",
       " 'signed',\n",
       " 'sizeof',\n",
       " 'static',\n",
       " 'struct',\n",
       " 'switch',\n",
       " 'typedef',\n",
       " 'union',\n",
       " 'unsigned',\n",
       " 'void',\n",
       " 'volatile',\n",
       " 'while',\n",
       " '_Bool',\n",
       " '_Complex',\n",
       " '_Imaginary']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"auto break case char const continue default do double else enum extern float for goto if inline int long register restrict return short signed sizeof static struct switch typedef union unsigned void volatile while _Bool _Complex _Imaginary\"\n",
    "\n",
    "l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '}',\n",
       " '.',\n",
       " '->',\n",
       " '++',\n",
       " '--',\n",
       " '&',\n",
       " '*',\n",
       " '+',\n",
       " '-',\n",
       " '˜',\n",
       " '!',\n",
       " '/',\n",
       " '%',\n",
       " '<<',\n",
       " '>>',\n",
       " '<',\n",
       " '>',\n",
       " '<=',\n",
       " '>=',\n",
       " '==',\n",
       " '!=',\n",
       " 'ˆ',\n",
       " '|',\n",
       " '&&',\n",
       " '||',\n",
       " '?',\n",
       " ':',\n",
       " ';',\n",
       " '...',\n",
       " '=',\n",
       " '*=',\n",
       " '/=',\n",
       " '%=',\n",
       " '+=',\n",
       " '-=',\n",
       " '<<=',\n",
       " '>>=',\n",
       " '&=',\n",
       " 'ˆ=',\n",
       " '|=',\n",
       " ',',\n",
       " '#',\n",
       " '##',\n",
       " '<:',\n",
       " ':>',\n",
       " '<%',\n",
       " '%>',\n",
       " '%:',\n",
       " '%:%:']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"[ ] ( ) { } . -> ++ -- & * + - ˜ ! / % << >> < > <= >= == != ˆ | && || ? : ; ... = *= /= %= += -= <<= >>= &= ˆ= |= , # ## <: :> <% %> %: %:%:\"\n",
    "l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnreachableError",
     "evalue": "<function choice.<locals>.out_parser at 0x747ee4b96160>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnreachableError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 22\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m      2\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mtypedef struct\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m} Elf64_Ehdr;\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m\"\"\"\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m ts \u001b[39m=\u001b[39m parse_token_stream(LexerState(df))\u001b[39m.\u001b[39munwrap()\n\u001b[1;32m     23\u001b[0m \u001b[39m# print(ts)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m Struct\u001b[39m.\u001b[39mparse(ParserState(ts[\u001b[39m1\u001b[39m:]))\n",
      "File \u001b[0;32m~/Desktop/dev/compilers/at1/lib/parsing/combinator.py:261\u001b[0m, in \u001b[0;36mresult_runner.<locals>.out_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m         res \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(res)\n\u001b[1;32m    262\u001b[0m         \u001b[39mmatch\u001b[39;00m res:\n\u001b[1;32m    263\u001b[0m             \u001b[39mcase\u001b[39;00m Err(e):\n",
      "File \u001b[0;32m~/Desktop/dev/compilers/at1/lib/parsing/c/lexer.py:588\u001b[0m, in \u001b[0;36mparse_token_stream\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    586\u001b[0m rest \u001b[39m=\u001b[39m state\n\u001b[1;32m    587\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mlen\u001b[39m(rest) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 588\u001b[0m     token, rest \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m dispatch(rest)(rest)\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m token \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         output\u001b[39m.\u001b[39mappend(token)\n",
      "File \u001b[0;32m~/Desktop/dev/compilers/at1/lib/parsing/combinator.py:74\u001b[0m, in \u001b[0;36mmap.<locals>.out_parser\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mout_parser\u001b[39m(state: S) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ParserRet[S, R, E]:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mmatch\u001b[39;00m parser(state):\n\u001b[1;32m     75\u001b[0m         \u001b[39mcase\u001b[39;00m Err(e):\n\u001b[1;32m     76\u001b[0m             \u001b[39mreturn\u001b[39;00m Err(e)\n",
      "File \u001b[0;32m~/Desktop/dev/compilers/at1/lib/parsing/combinator.py:177\u001b[0m, in \u001b[0;36mchoice.<locals>.out_parser\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mout_parser\u001b[39m(state: S) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ParserRet[T, S, E]:\n\u001b[1;32m    176\u001b[0m     \u001b[39mfor\u001b[39;00m parser \u001b[39min\u001b[39;00m parsers:\n\u001b[0;32m--> 177\u001b[0m         \u001b[39mmatch\u001b[39;00m parser(state):\n\u001b[1;32m    178\u001b[0m             \u001b[39mcase\u001b[39;00m Err(e):\n\u001b[1;32m    179\u001b[0m                 \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/dev/compilers/at1/lib/parsing/combinator.py:268\u001b[0m, in \u001b[0;36mresult_runner.<locals>.out_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m             res \u001b[39m=\u001b[39m r\n\u001b[1;32m    267\u001b[0m         \u001b[39mcase\u001b[39;00m e:\n\u001b[0;32m--> 268\u001b[0m             \u001b[39mraise\u001b[39;00m UnreachableError(e)\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m st:\n\u001b[1;32m    271\u001b[0m     \u001b[39mmatch\u001b[39;00m st\u001b[39m.\u001b[39mvalue:\n",
      "\u001b[0;31mUnreachableError\u001b[0m: <function choice.<locals>.out_parser at 0x747ee4b96160>"
     ]
    }
   ],
   "source": [
    "df = str(\n",
    "\"\"\"\n",
    "typedef struct\n",
    "{\n",
    "    uchar_t e_ident[16]; /* ELF identification */\n",
    "    Elf64_Half e_type; /* Object file type */\n",
    "    Elf64_Half e_machine; /* Machine type */\n",
    "    Elf64_Word e_version; /* Object file version */\n",
    "    Elf64_Addr e_entry; /* Entry point address */\n",
    "    Elf64_Off e_phoff; /* Program header offset */\n",
    "    Elf64_Off e_shoff; /* Section header offset */\n",
    "    Elf64_Word e_flags; /* Processor-specific flags */\n",
    "    Elf64_Half e_ehsize; /* ELF header size */\n",
    "    Elf64_Half e_phentsize; /* Size of program header entry */\n",
    "    Elf64_Half e_phnum; /* Number of program header entries */\n",
    "    Elf64_Half e_shentsize; /* Size of section header entry */\n",
    "    Elf64_Half e_shnum; /* Number of section header entries */\n",
    "    Elf64_Half e_shstrndx; /* Section name string table index */\n",
    "} Elf64_Ehdr;\n",
    "\"\"\")\n",
    "\n",
    "ts = parse_token_stream(LexerState(df)).unwrap()\n",
    "# print(ts)\n",
    "\n",
    "Struct.parse(ParserState(ts[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    return 3\n",
    "\n",
    "match foo():\n",
    "    case i, j: print(i, j)\n",
    "    case i: print(i)\n",
    "# i, j = foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 1), match=' '>\n",
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.match(r\"\\s+\", \"\"))\n",
    "print(re.match(r\"\\s+\", \" \"))\n",
    "\n",
    "m = re.match(r\"\\s+\", \" \")\n",
    "print(m.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match=' \\n   '>\n",
      "(' ',)\n"
     ]
    }
   ],
   "source": [
    "m = re.match(r\"\\s(\\s)+\", \" \\n   \")\n",
    "print(m)\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__class__: <class 're.Match'>\n",
      "__class_getitem__: <built-in method __class_getitem__ of type object at 0x55dfeb4a69d0>\n",
      "__copy__: <built-in method __copy__ of re.Match object at 0x7fa272811cf0>\n",
      "__deepcopy__: <built-in method __deepcopy__ of re.Match object at 0x7fa272811cf0>\n",
      "__delattr__: <method-wrapper '__delattr__' of re.Match object at 0x7fa272811cf0>\n",
      "__dir__: <built-in method __dir__ of re.Match object at 0x7fa272811cf0>\n",
      "__doc__: The result of re.match() and re.search().\n",
      "Match objects always have a boolean value of True.\n",
      "__eq__: <method-wrapper '__eq__' of re.Match object at 0x7fa272811cf0>\n",
      "__format__: <built-in method __format__ of re.Match object at 0x7fa272811cf0>\n",
      "__ge__: <method-wrapper '__ge__' of re.Match object at 0x7fa272811cf0>\n",
      "__getattribute__: <method-wrapper '__getattribute__' of re.Match object at 0x7fa272811cf0>\n",
      "__getitem__: <method-wrapper '__getitem__' of re.Match object at 0x7fa272811cf0>\n",
      "__getstate__: <built-in method __getstate__ of re.Match object at 0x7fa272811cf0>\n",
      "__gt__: <method-wrapper '__gt__' of re.Match object at 0x7fa272811cf0>\n",
      "__hash__: <method-wrapper '__hash__' of re.Match object at 0x7fa272811cf0>\n",
      "__init__: <method-wrapper '__init__' of re.Match object at 0x7fa272811cf0>\n",
      "__init_subclass__: <built-in method __init_subclass__ of type object at 0x55dfeb4a69d0>\n",
      "__le__: <method-wrapper '__le__' of re.Match object at 0x7fa272811cf0>\n",
      "__lt__: <method-wrapper '__lt__' of re.Match object at 0x7fa272811cf0>\n",
      "__module__: re\n",
      "__ne__: <method-wrapper '__ne__' of re.Match object at 0x7fa272811cf0>\n",
      "__new__: <built-in method __new__ of type object at 0x7fa276370400>\n",
      "__reduce__: <built-in method __reduce__ of re.Match object at 0x7fa272811cf0>\n",
      "__reduce_ex__: <built-in method __reduce_ex__ of re.Match object at 0x7fa272811cf0>\n",
      "__repr__: <method-wrapper '__repr__' of re.Match object at 0x7fa272811cf0>\n",
      "__setattr__: <method-wrapper '__setattr__' of re.Match object at 0x7fa272811cf0>\n",
      "__sizeof__: <built-in method __sizeof__ of re.Match object at 0x7fa272811cf0>\n",
      "__str__: <method-wrapper '__str__' of re.Match object at 0x7fa272811cf0>\n",
      "__subclasshook__: <built-in method __subclasshook__ of type object at 0x55dfeb4a69d0>\n",
      "end: <built-in method end of re.Match object at 0x7fa272811cf0>\n",
      "endpos: 9\n",
      "expand: <built-in method expand of re.Match object at 0x7fa272811cf0>\n",
      "group: <built-in method group of re.Match object at 0x7fa272811cf0>\n",
      "groupdict: <built-in method groupdict of re.Match object at 0x7fa272811cf0>\n",
      "groups: <built-in method groups of re.Match object at 0x7fa272811cf0>\n",
      "lastgroup: None\n",
      "lastindex: 1\n",
      "pos: 0\n",
      "re: re.compile('(ab)+')\n",
      "regs: ((0, 6), (4, 6))\n",
      "span: <built-in method span of re.Match object at 0x7fa272811cf0>\n",
      "start: <built-in method start of re.Match object at 0x7fa272811cf0>\n",
      "string: ababab ab\n",
      "ababab\n"
     ]
    }
   ],
   "source": [
    "# print(c_lexer.parse_keyword(\"if\", c_lexer.LexerData(0,0)))\n",
    "m = re.match(r\"(ab)+\", \"ababab ab\")\n",
    "for x in dir(m):\n",
    "    print(f\"{x}:\", eval(\"m.\"+x))\n",
    "\n",
    "print(m.group())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': 1, 'line': 1, 'text': 'typedef', 'type': 'identifier'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "d = LexerData(1, 1)\n",
    "t, r, rd = parse_keyword(df[1:], d)\n",
    "pprint(t.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ident' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ident \u001b[39m=\u001b[39m Ident(\u001b[39m'\u001b[39m\u001b[39mvar\u001b[39m\u001b[39m'\u001b[39m, Span(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[39m# ident.__dict__\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ident\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ident' is not defined"
     ]
    }
   ],
   "source": [
    "ident = Ident('var', Span(0,1,1,0,1,1))\n",
    "# ident.__dict__\n",
    "ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(IntegerConstantBase.DEC)\n",
    "IntegerConstantBase.DEC == IntegerConstantBase.HEX\n",
    "\n",
    "IntegerConstantBase.DEC.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Some(value=16), 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Self, Callable\n",
    "from result import *\n",
    "\n",
    "def monad_runner(f):\n",
    "    def out_f(*args, **kwargs):\n",
    "        gen = f(*args, **kwargs)\n",
    "        res = gen.send(None)\n",
    "        while True:\n",
    "            try:\n",
    "                res = res.bind(gen.send)\n",
    "            except StopIteration as st:\n",
    "                return st.value\n",
    "\n",
    "    return out_f\n",
    "    \n",
    "@dataclass\n",
    "class Some[T]:\n",
    "    value: T | None\n",
    "    \n",
    "    # @classmethod\n",
    "    # def pure(self)\n",
    "    def bind[R](self, f: Callable[[T], Self]) -> Self:\n",
    "        \"Self[T], Callable[[T], Self[R]] -> Self[R]\"\n",
    "        return f(self.value)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Nothing[T]:\n",
    "    \n",
    "    def bind[R](self, f:Callable[[T], Self]) -> Self:\n",
    "        \"Self[T], Callable[[T], Self[R]] -> Self[R]\"\n",
    "        return Nothing()\n",
    "    \n",
    "# type Maybe[T] = Some[T] | None\n",
    "\n",
    "# def bind[T, R](m: Maybe[T], f: Callable[[T], Maybe[R]]) -> Maybe[R]:\n",
    "#     match m:\n",
    "#         case Some(t): return f(t)\n",
    "#         case None: return None\n",
    "\n",
    "\n",
    "@monad_runner\n",
    "def do_maybe(i: int):\n",
    "    res = yield Some(i*2) if i < 3 else Nothing()\n",
    "    res = yield Some(res*2) if i < 3 else Nothing()\n",
    "    return Some(res*2), 3\n",
    "\n",
    "\n",
    "\n",
    "# do_maybe(2).send(None)\n",
    "do_maybe(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@result_runner\n",
    "def f(i):\n",
    "    res = yield Ok(i*2) if i < 3 else Err(\"msg\")\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "from math import inf\n",
      "from typing import Callable\n",
      "from result import *\n",
      "\n",
      "\n",
      "type ParserRet[T, S, E] = Result[tuple[T, S, E], E[S]]\n",
      "type Parser[T, S, E] = Callable[[S], ParserRet[T, S, E]]\n",
      "\n",
      "\n",
      "def range[T, S, E](parser: Parser[T, S, E], min: int, max: int) -> Parser[list[T], S]:\n",
      "    # assert min <= max\n",
      "    def out_parser(s: S) -> ParserRet[S, list[T]]:\n",
      "        tokens = []\n",
      "        for _ in __builtins__.range(min):\n",
      "            match parser(s, data):\n",
      "                case token, rest, next_data:\n",
      "                    tokens.append(token)\n",
      "                    s = rest\n",
      "                    data = next_data\n",
      "                case None: return None\n",
      "\n",
      "        for _ in __builtins__.range(max - min):\n",
      "            match parser(s, data):\n",
      "                case token, rest, next_data:\n",
      "                    tokens.append(token)\n",
      "                    s = rest\n",
      "                    data = next_data\n",
      "                case None: break\n",
      "\n",
      "        return (tokens, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def optional[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 0, 1)\n",
      "\n",
      "\n",
      "def many[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 0, inf)\n",
      "\n",
      "\n",
      "def some[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 1, inf)\n",
      "\n",
      "\n",
      "def map[S, T, R](parser: Parser[T, S, E], fn: Callable[[T], R]) -> Parser[S, R]:\n",
      "    def out_parser(s: D) -> ParserRet[S, R]:\n",
      "        match parser(s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data: return (fn(res), rest, rest_data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def filter[T, S, E](parser: Parser[T, S, E], pred: Callable[[T], bool]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        match parser(s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data: \n",
      "                if not pred(res):\n",
      "                    return None\n",
      "                return (res, rest, rest_data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def sequence[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[list[T], S]:\n",
      "    def out_parser(data: D) -> ParserRet[S, list[T]]:\n",
      "        result = []\n",
      "        for parser in parsers:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case res, rest, rest_data:\n",
      "                    result.append(res)\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def first[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        assert len(parsers) > 0\n",
      "\n",
      "        match parsers[0](s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data:\n",
      "                result = res\n",
      "                s = rest\n",
      "                data = rest_data\n",
      "\n",
      "        for parser in parsers[1:]:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case _, rest, rest_data:\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def last[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        assert len(parsers) > 0\n",
      "\n",
      "        for parser in parsers[:-1]:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case _, rest, rest_data:\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        match parsers[-1](s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data:\n",
      "                result = res\n",
      "                s = rest\n",
      "                data = rest_data\n",
      "\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def choice[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        for parser in parsers:\n",
      "            match parser(s, data):\n",
      "                case None: continue\n",
      "                case res, rest, rest_data:\n",
      "                    return (res, rest, rest_data)\n",
      "\n",
      "        return None\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "\n",
      "def between[T, S, E](left: Parser[T, S, E], right: Parser[T, S, E], parser: Parser[T, S, E]) -> Parser[T, S, E]:\n",
      "    def middle(list: list):\n",
      "        list[1].span = Span.from_spans(list[0].span, list[1].span)\n",
      "        return list[1]\n",
      "\n",
      "    return map(\n",
      "        sequence([\n",
      "            left, parser, right\n",
      "        ]),\n",
      "            middle\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"../lib/parsing/combinator.py\") as ifile:\n",
    "    s = str(ifile.read())\n",
    "\n",
    "re.findall()\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def suffix(state: LexerState) -> LexerRet[IntegerConstantType]:\n",
    "    match parse_re(\n",
    "        # r\"(u|U)(l|L)? | (u|U)(ll|LL) | (l|L)(u|U)? | (ll|LL)(u|U)?\"\n",
    "        r\"(u|U)(ll|LL)|(u|U)(l|L)?|(ll|LL)(u|U)?|(l|L)(u|U)?\"\n",
    "    )(state):\n",
    "        case Err(_): return Ok((IntegerConstantType.INT, state))\n",
    "        case Ok((suf, rest)): print(suf)\n",
    "        case e: raise UnreachableError(e)\n",
    "        \n",
    "    if 'u' in suf or 'U' in suf:\n",
    "        if len(suf) == 1:\n",
    "            return Ok((IntegerConstantType.UINT, rest))\n",
    "        elif len(suf) == 2:\n",
    "            return Ok((IntegerConstantType.ULONG, rest))\n",
    "        elif len(suf) == 3:\n",
    "            return Ok((IntegerConstantType.ULLONG, rest))\n",
    "    else:\n",
    "        if len(suf) == 1:\n",
    "            return Ok((IntegerConstantType.LONG, rest))\n",
    "        elif len(suf) == 2:\n",
    "            return Ok((IntegerConstantType.LLONG, rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ull\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ok((<IntegerConstantType.ULLONG: 'llu'>, LexerState(text='ull', index=3, line=1, col=4)))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suffix(LexerState(\"ull\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='lu'>\n"
     ]
    }
   ],
   "source": [
    "print(re.match(r\"(u|U)(ll|LL)|(u|U)(l|L)?|(ll|LL)(u|U)?|(l|L)(u|U)?\", \"lul\"))\n",
    "# print(re.match(r\"((a|b)(a|b)?)|c\", \"c\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea2d0de66aaa89d877809e6e9dcecf5d9c95e6fc0f4afd0a1d8731ae6cea6e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
