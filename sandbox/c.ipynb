{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/mbgl/Desktop/dev/compilers/at1/sandbox', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python312.zip', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12/lib-dynload', '', '/home/mbgl/.config/pyenv/versions/3.12.1/lib/python3.12/site-packages']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'Callable',\n",
       " 'CharacterLiteral',\n",
       " 'Enum',\n",
       " 'Err',\n",
       " 'Expr',\n",
       " 'FloatingLiteral',\n",
       " 'Generator',\n",
       " 'Ident',\n",
       " 'In',\n",
       " 'IntegerConstantBase',\n",
       " 'IntegerConstantType',\n",
       " 'IntegerLiteral',\n",
       " 'KEYWORDS',\n",
       " 'Keyword',\n",
       " 'Lexer',\n",
       " 'LexerError',\n",
       " 'LexerRet',\n",
       " 'LexerState',\n",
       " 'Literal',\n",
       " 'Ok',\n",
       " 'OkErr',\n",
       " 'Optional',\n",
       " 'Out',\n",
       " 'PARSE_OBJECTS_DEFAULT',\n",
       " 'PUNCTUATORS',\n",
       " 'Parser',\n",
       " 'ParserError',\n",
       " 'ParserRet',\n",
       " 'ParserState',\n",
       " 'Punct',\n",
       " 'Result',\n",
       " 'Self',\n",
       " 'Span',\n",
       " 'StringLiteral',\n",
       " 'Struct',\n",
       " 'Token',\n",
       " 'TypeAlias',\n",
       " 'TypeVar',\n",
       " 'UnwrapError',\n",
       " '_',\n",
       " '_1',\n",
       " '_10',\n",
       " '_11',\n",
       " '_14',\n",
       " '_15',\n",
       " '_2',\n",
       " '_4',\n",
       " '_5',\n",
       " '__',\n",
       " '___',\n",
       " '__builtin__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '__vsc_ipynb_file__',\n",
       " '_dh',\n",
       " '_i',\n",
       " '_i1',\n",
       " '_i10',\n",
       " '_i11',\n",
       " '_i12',\n",
       " '_i13',\n",
       " '_i14',\n",
       " '_i15',\n",
       " '_i16',\n",
       " '_i2',\n",
       " '_i3',\n",
       " '_i4',\n",
       " '_i5',\n",
       " '_i6',\n",
       " '_i7',\n",
       " '_i8',\n",
       " '_i9',\n",
       " '_ih',\n",
       " '_ii',\n",
       " '_iii',\n",
       " '_oh',\n",
       " 'as_async_result',\n",
       " 'as_result',\n",
       " 'auto',\n",
       " 'between',\n",
       " 'combinator',\n",
       " 'copy',\n",
       " 'dataclass',\n",
       " 'do',\n",
       " 'do_async',\n",
       " 'err',\n",
       " 'exit',\n",
       " 'field',\n",
       " 'get_ipython',\n",
       " 'ident',\n",
       " 'imp',\n",
       " 'inf',\n",
       " 'infer_span',\n",
       " 'is_err',\n",
       " 'is_ok',\n",
       " 'keyword',\n",
       " 'lib',\n",
       " 'open',\n",
       " 'os',\n",
       " 'parse_end_of_input',\n",
       " 'parse_escape_sequence',\n",
       " 'parse_re',\n",
       " 'parse_string',\n",
       " 'parse_token',\n",
       " 'parse_whitespace',\n",
       " 'parser_gen_runner',\n",
       " 'punct',\n",
       " 'quit',\n",
       " 're',\n",
       " 's',\n",
       " 'skip_whitespace',\n",
       " 'sys',\n",
       " 'token',\n",
       " 'tokenize',\n",
       " 'wraps']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib as imp\n",
    "# imp.invalidate_caches()\n",
    "# sys.path.insert(1, '../lib/parsing')\n",
    "print(sys.path)\n",
    "os.path.abspath(os.curdir)\n",
    "os.__file__\n",
    "# from c_lexer import *\n",
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mbgl/Desktop'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"..\")\n",
    "os.path.abspath(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.parsing.c_lexer\n",
    "import lib.parsing.c_parser\n",
    "import lib.parsing.combinator\n",
    "imp.reload(lib.parsing.c_lexer)\n",
    "imp.reload(lib.parsing.c_parser)\n",
    "imp.reload(lib.parsing.combinator)\n",
    "from lib.parsing.c_lexer import *\n",
    "from lib.parsing.c_parser import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok(('test', LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok(('test', LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok((Ident(name='test', span=Span(index=0, line=1, col=1, end_index=4, end_line=1, end_col=5)), LexerState(text='test', index=4, line=1, col=5)))\n",
      "Ok((Keyword(ident=Ident(name='while', span=Span(index=0, line=1, col=1, end_index=5, end_line=1, end_col=6)), span=Span(index=0, line=1, col=1, end_index=5, end_line=1, end_col=6)), LexerState(text='while', index=5, line=1, col=6)))\n",
      "Ok((Punct(value='<<', span=Span(index=0, line=1, col=1, end_index=2, end_line=1, end_col=3)), LexerState(text='<<', index=2, line=1, col=3)))\n",
      "Ok((Punct(value='[', span=Span(index=0, line=1, col=1, end_index=1, end_line=1, end_col=2)), LexerState(text='[]', index=1, line=1, col=2)))\n",
      "Err(LexerError(state=LexerState(text='_]', index=0, line=1, col=1), expected='punctuator'))\n",
      "s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([Keyword(ident=Ident(name='while', span=Span(index=0, line=1, col=1, end_index=5, end_line=1, end_col=6)), span=Span(index=0, line=1, col=1, end_index=5, end_line=1, end_col=6)),\n",
       "  Ident(name='true', span=Span(index=6, line=1, col=7, end_index=10, end_line=1, end_col=11)),\n",
       "  Punct(value='{', span=Span(index=11, line=2, col=0, end_index=12, end_line=2, end_col=1)),\n",
       "  Ident(name='statement', span=Span(index=12, line=2, col=1, end_index=21, end_line=2, end_col=10)),\n",
       "  Punct(value='(', span=Span(index=21, line=2, col=10, end_index=22, end_line=2, end_col=11)),\n",
       "  Punct(value=')', span=Span(index=22, line=2, col=11, end_index=23, end_line=2, end_col=12)),\n",
       "  Punct(value=';', span=Span(index=23, line=2, col=12, end_index=24, end_line=2, end_col=13)),\n",
       "  Punct(value='}', span=Span(index=24, line=2, col=13, end_index=25, end_line=2, end_col=14))],\n",
       " LexerState(text='while true\\n{statement();}', index=25, line=2, col=14))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = LexerState(\"test\")\n",
    "print(parse_string(\"test\")(s))\n",
    "print(parse_re(\"test\")(s))\n",
    "print(Ident.parse(s))\n",
    "s = LexerState(\"while\")\n",
    "print(Keyword.parse(s))\n",
    "print(Punct.parse(LexerState(\"<<\")))\n",
    "print(Punct.parse(LexerState(\"[]\")))\n",
    "print(Punct.parse(LexerState(\"_]\")))\n",
    "\n",
    "print(LexerState(\"state\")[0])\n",
    "\n",
    "s = LexerState(\"while true\\n{statement();}\")\n",
    "tokenize(s).unwrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts, rest = tokenize(LexerState(\"struct test_s {\\nint i; double d;};\")).unwrap()\n",
    "# print(ts)\n",
    "# Struct.parse(ParserState(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('a')\n",
    "s = Span\n",
    "s()\n",
    "Ident(\"a\", Span(1)) == Ident(\"a\", Span(2))\n",
    "Keyword(Ident(\"a\", Span(1))) == Keyword(Ident(\"a\", Span(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['auto',\n",
       " 'break',\n",
       " 'case',\n",
       " 'char',\n",
       " 'const',\n",
       " 'continue',\n",
       " 'default',\n",
       " 'do',\n",
       " 'double',\n",
       " 'else',\n",
       " 'enum',\n",
       " 'extern',\n",
       " 'float',\n",
       " 'for',\n",
       " 'goto',\n",
       " 'if',\n",
       " 'inline',\n",
       " 'int',\n",
       " 'long',\n",
       " 'register',\n",
       " 'restrict',\n",
       " 'return',\n",
       " 'short',\n",
       " 'signed',\n",
       " 'sizeof',\n",
       " 'static',\n",
       " 'struct',\n",
       " 'switch',\n",
       " 'typedef',\n",
       " 'union',\n",
       " 'unsigned',\n",
       " 'void',\n",
       " 'volatile',\n",
       " 'while',\n",
       " '_Bool',\n",
       " '_Complex',\n",
       " '_Imaginary']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"auto break case char const continue default do double else enum extern float for goto if inline int long register restrict return short signed sizeof static struct switch typedef union unsigned void volatile while _Bool _Complex _Imaginary\"\n",
    "\n",
    "l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " ']',\n",
       " '(',\n",
       " ')',\n",
       " '{',\n",
       " '}',\n",
       " '.',\n",
       " '->',\n",
       " '++',\n",
       " '--',\n",
       " '&',\n",
       " '*',\n",
       " '+',\n",
       " '-',\n",
       " '˜',\n",
       " '!',\n",
       " '/',\n",
       " '%',\n",
       " '<<',\n",
       " '>>',\n",
       " '<',\n",
       " '>',\n",
       " '<=',\n",
       " '>=',\n",
       " '==',\n",
       " '!=',\n",
       " 'ˆ',\n",
       " '|',\n",
       " '&&',\n",
       " '||',\n",
       " '?',\n",
       " ':',\n",
       " ';',\n",
       " '...',\n",
       " '=',\n",
       " '*=',\n",
       " '/=',\n",
       " '%=',\n",
       " '+=',\n",
       " '-=',\n",
       " '<<=',\n",
       " '>>=',\n",
       " '&=',\n",
       " 'ˆ=',\n",
       " '|=',\n",
       " ',',\n",
       " '#',\n",
       " '##',\n",
       " '<:',\n",
       " ':>',\n",
       " '<%',\n",
       " '%>',\n",
       " '%:',\n",
       " '%:%:']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = \"[ ] ( ) { } . -> ++ -- & * + - ˜ ! / % << >> < > <= >= == != ˆ | && || ? : ; ... = *= /= %= += -= <<= >>= &= ˆ= |= , # ## <: :> <% %> %: %:%:\"\n",
    "l.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = str(\n",
    "\"\"\"\n",
    "typedef struct\n",
    "{\n",
    "    uchar_t e_ident[16]; /* ELF identification */\n",
    "    Elf64_Half e_type; /* Object file type */\n",
    "    Elf64_Half e_machine; /* Machine type */\n",
    "    Elf64_Word e_version; /* Object file version */\n",
    "    Elf64_Addr e_entry; /* Entry point address */\n",
    "    Elf64_Off e_phoff; /* Program header offset */\n",
    "    Elf64_Off e_shoff; /* Section header offset */\n",
    "    Elf64_Word e_flags; /* Processor-specific flags */\n",
    "    Elf64_Half e_ehsize; /* ELF header size */\n",
    "    Elf64_Half e_phentsize; /* Size of program header entry */\n",
    "    Elf64_Half e_phnum; /* Number of program header entries */\n",
    "    Elf64_Half e_shentsize; /* Size of section header entry */\n",
    "    Elf64_Half e_shnum; /* Number of section header entries */\n",
    "    Elf64_Half e_shstrndx; /* Section name string table index */\n",
    "} Elf64_Ehdr;\n",
    "\"\"\")\n",
    "\n",
    "# print(str(df[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    return 3\n",
    "\n",
    "match foo():\n",
    "    case i, j: print(i, j)\n",
    "    case i: print(i)\n",
    "# i, j = foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 1), match=' '>\n",
      "(0, 1)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "print(re.match(r\"\\s+\", \"\"))\n",
    "print(re.match(r\"\\s+\", \" \"))\n",
    "\n",
    "m = re.match(r\"\\s+\", \" \")\n",
    "print(m.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 5), match=' \\n   '>\n",
      "(' ',)\n"
     ]
    }
   ],
   "source": [
    "m = re.match(r\"\\s(\\s)+\", \" \\n   \")\n",
    "print(m)\n",
    "print(m.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__class__: <class 're.Match'>\n",
      "__class_getitem__: <built-in method __class_getitem__ of type object at 0x55dfeb4a69d0>\n",
      "__copy__: <built-in method __copy__ of re.Match object at 0x7fa272811cf0>\n",
      "__deepcopy__: <built-in method __deepcopy__ of re.Match object at 0x7fa272811cf0>\n",
      "__delattr__: <method-wrapper '__delattr__' of re.Match object at 0x7fa272811cf0>\n",
      "__dir__: <built-in method __dir__ of re.Match object at 0x7fa272811cf0>\n",
      "__doc__: The result of re.match() and re.search().\n",
      "Match objects always have a boolean value of True.\n",
      "__eq__: <method-wrapper '__eq__' of re.Match object at 0x7fa272811cf0>\n",
      "__format__: <built-in method __format__ of re.Match object at 0x7fa272811cf0>\n",
      "__ge__: <method-wrapper '__ge__' of re.Match object at 0x7fa272811cf0>\n",
      "__getattribute__: <method-wrapper '__getattribute__' of re.Match object at 0x7fa272811cf0>\n",
      "__getitem__: <method-wrapper '__getitem__' of re.Match object at 0x7fa272811cf0>\n",
      "__getstate__: <built-in method __getstate__ of re.Match object at 0x7fa272811cf0>\n",
      "__gt__: <method-wrapper '__gt__' of re.Match object at 0x7fa272811cf0>\n",
      "__hash__: <method-wrapper '__hash__' of re.Match object at 0x7fa272811cf0>\n",
      "__init__: <method-wrapper '__init__' of re.Match object at 0x7fa272811cf0>\n",
      "__init_subclass__: <built-in method __init_subclass__ of type object at 0x55dfeb4a69d0>\n",
      "__le__: <method-wrapper '__le__' of re.Match object at 0x7fa272811cf0>\n",
      "__lt__: <method-wrapper '__lt__' of re.Match object at 0x7fa272811cf0>\n",
      "__module__: re\n",
      "__ne__: <method-wrapper '__ne__' of re.Match object at 0x7fa272811cf0>\n",
      "__new__: <built-in method __new__ of type object at 0x7fa276370400>\n",
      "__reduce__: <built-in method __reduce__ of re.Match object at 0x7fa272811cf0>\n",
      "__reduce_ex__: <built-in method __reduce_ex__ of re.Match object at 0x7fa272811cf0>\n",
      "__repr__: <method-wrapper '__repr__' of re.Match object at 0x7fa272811cf0>\n",
      "__setattr__: <method-wrapper '__setattr__' of re.Match object at 0x7fa272811cf0>\n",
      "__sizeof__: <built-in method __sizeof__ of re.Match object at 0x7fa272811cf0>\n",
      "__str__: <method-wrapper '__str__' of re.Match object at 0x7fa272811cf0>\n",
      "__subclasshook__: <built-in method __subclasshook__ of type object at 0x55dfeb4a69d0>\n",
      "end: <built-in method end of re.Match object at 0x7fa272811cf0>\n",
      "endpos: 9\n",
      "expand: <built-in method expand of re.Match object at 0x7fa272811cf0>\n",
      "group: <built-in method group of re.Match object at 0x7fa272811cf0>\n",
      "groupdict: <built-in method groupdict of re.Match object at 0x7fa272811cf0>\n",
      "groups: <built-in method groups of re.Match object at 0x7fa272811cf0>\n",
      "lastgroup: None\n",
      "lastindex: 1\n",
      "pos: 0\n",
      "re: re.compile('(ab)+')\n",
      "regs: ((0, 6), (4, 6))\n",
      "span: <built-in method span of re.Match object at 0x7fa272811cf0>\n",
      "start: <built-in method start of re.Match object at 0x7fa272811cf0>\n",
      "string: ababab ab\n",
      "ababab\n"
     ]
    }
   ],
   "source": [
    "# print(c_lexer.parse_keyword(\"if\", c_lexer.LexerData(0,0)))\n",
    "m = re.match(r\"(ab)+\", \"ababab ab\")\n",
    "for x in dir(m):\n",
    "    print(f\"{x}:\", eval(\"m.\"+x))\n",
    "\n",
    "print(m.group())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col': 1, 'line': 1, 'text': 'typedef', 'type': 'identifier'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "d = LexerData(1, 1)\n",
    "t, r, rd = parse_keyword(df[1:], d)\n",
    "pprint(t.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ident' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ident \u001b[39m=\u001b[39m Ident(\u001b[39m'\u001b[39m\u001b[39mvar\u001b[39m\u001b[39m'\u001b[39m, Span(\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[39m# ident.__dict__\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ident\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ident' is not defined"
     ]
    }
   ],
   "source": [
    "ident = Ident('var', Span(0,1,1,0,1,1))\n",
    "# ident.__dict__\n",
    "ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEC'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(IntegerConstantBase.DEC)\n",
    "IntegerConstantBase.DEC == IntegerConstantBase.HEX\n",
    "\n",
    "IntegerConstantBase.DEC.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Some(value=16), 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Self, Callable\n",
    "from result import *\n",
    "\n",
    "def monad_runner(f):\n",
    "    def out_f(*args, **kwargs):\n",
    "        gen = f(*args, **kwargs)\n",
    "        res = gen.send(None)\n",
    "        while True:\n",
    "            try:\n",
    "                res = res.bind(gen.send)\n",
    "            except StopIteration as st:\n",
    "                return st.value\n",
    "\n",
    "    return out_f\n",
    "    \n",
    "@dataclass\n",
    "class Some[T]:\n",
    "    value: T | None\n",
    "    \n",
    "    # @classmethod\n",
    "    # def pure(self)\n",
    "    def bind[R](self, f: Callable[[T], Self]) -> Self:\n",
    "        \"Self[T], Callable[[T], Self[R]] -> Self[R]\"\n",
    "        return f(self.value)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Nothing[T]:\n",
    "    \n",
    "    def bind[R](self, f:Callable[[T], Self]) -> Self:\n",
    "        \"Self[T], Callable[[T], Self[R]] -> Self[R]\"\n",
    "        return Nothing()\n",
    "    \n",
    "# type Maybe[T] = Some[T] | None\n",
    "\n",
    "# def bind[T, R](m: Maybe[T], f: Callable[[T], Maybe[R]]) -> Maybe[R]:\n",
    "#     match m:\n",
    "#         case Some(t): return f(t)\n",
    "#         case None: return None\n",
    "\n",
    "\n",
    "@monad_runner\n",
    "def do_maybe(i: int):\n",
    "    res = yield Some(i*2) if i < 3 else Nothing()\n",
    "    res = yield Some(res*2) if i < 3 else Nothing()\n",
    "    return Some(res*2), 3\n",
    "\n",
    "\n",
    "\n",
    "# do_maybe(2).send(None)\n",
    "do_maybe(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@result_runner\n",
    "def f(i):\n",
    "    res = yield Ok(i*2) if i < 3 else Err(\"msg\")\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "from math import inf\n",
      "from typing import Callable\n",
      "from result import *\n",
      "\n",
      "\n",
      "type ParserRet[T, S, E] = Result[tuple[T, S, E], E[S]]\n",
      "type Parser[T, S, E] = Callable[[S], ParserRet[T, S, E]]\n",
      "\n",
      "\n",
      "def range[T, S, E](parser: Parser[T, S, E], min: int, max: int) -> Parser[list[T], S]:\n",
      "    # assert min <= max\n",
      "    def out_parser(s: S) -> ParserRet[S, list[T]]:\n",
      "        tokens = []\n",
      "        for _ in __builtins__.range(min):\n",
      "            match parser(s, data):\n",
      "                case token, rest, next_data:\n",
      "                    tokens.append(token)\n",
      "                    s = rest\n",
      "                    data = next_data\n",
      "                case None: return None\n",
      "\n",
      "        for _ in __builtins__.range(max - min):\n",
      "            match parser(s, data):\n",
      "                case token, rest, next_data:\n",
      "                    tokens.append(token)\n",
      "                    s = rest\n",
      "                    data = next_data\n",
      "                case None: break\n",
      "\n",
      "        return (tokens, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def optional[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 0, 1)\n",
      "\n",
      "\n",
      "def many[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 0, inf)\n",
      "\n",
      "\n",
      "def some[T, S, E](parser: Parser[T, S, E]) -> Parser[list[T], S]:\n",
      "    return range(parser, 1, inf)\n",
      "\n",
      "\n",
      "def map[S, T, R](parser: Parser[T, S, E], fn: Callable[[T], R]) -> Parser[S, R]:\n",
      "    def out_parser(s: D) -> ParserRet[S, R]:\n",
      "        match parser(s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data: return (fn(res), rest, rest_data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def filter[T, S, E](parser: Parser[T, S, E], pred: Callable[[T], bool]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        match parser(s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data: \n",
      "                if not pred(res):\n",
      "                    return None\n",
      "                return (res, rest, rest_data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def sequence[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[list[T], S]:\n",
      "    def out_parser(data: D) -> ParserRet[S, list[T]]:\n",
      "        result = []\n",
      "        for parser in parsers:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case res, rest, rest_data:\n",
      "                    result.append(res)\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def first[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        assert len(parsers) > 0\n",
      "\n",
      "        match parsers[0](s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data:\n",
      "                result = res\n",
      "                s = rest\n",
      "                data = rest_data\n",
      "\n",
      "        for parser in parsers[1:]:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case _, rest, rest_data:\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def last[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        assert len(parsers) > 0\n",
      "\n",
      "        for parser in parsers[:-1]:\n",
      "            match parser(s, data):\n",
      "                case None: return None\n",
      "                case _, rest, rest_data:\n",
      "                    s = rest\n",
      "                    data = rest_data\n",
      "\n",
      "        match parsers[-1](s, data):\n",
      "            case None: return None\n",
      "            case res, rest, rest_data:\n",
      "                result = res\n",
      "                s = rest\n",
      "                data = rest_data\n",
      "\n",
      "\n",
      "        return (result, s, data)\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "def choice[T, S, E](parsers: list[Parser[T, S, E]]) -> Parser[T, S, E]:\n",
      "    def out_parser(data: D) -> ParserRet[T, S, E]:\n",
      "        for parser in parsers:\n",
      "            match parser(s, data):\n",
      "                case None: continue\n",
      "                case res, rest, rest_data:\n",
      "                    return (res, rest, rest_data)\n",
      "\n",
      "        return None\n",
      "\n",
      "    return out_parser\n",
      "\n",
      "\n",
      "def between[T, S, E](left: Parser[T, S, E], right: Parser[T, S, E], parser: Parser[T, S, E]) -> Parser[T, S, E]:\n",
      "    def middle(list: list):\n",
      "        list[1].span = Span.from_spans(list[0].span, list[1].span)\n",
      "        return list[1]\n",
      "\n",
      "    return map(\n",
      "        sequence([\n",
      "            left, parser, right\n",
      "        ]),\n",
      "            middle\n",
      "        )\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"../lib/parsing/combinator.py\") as ifile:\n",
    "    s = str(ifile.read())\n",
    "\n",
    "re.findall()\n",
    "print(s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea2d0de66aaa89d877809e6e9dcecf5d9c95e6fc0f4afd0a1d8731ae6cea6e04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
